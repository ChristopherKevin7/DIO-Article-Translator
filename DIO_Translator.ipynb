{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YDerkWD6KAhp",
    "outputId": "bad65455-2cea-402d-9121-d965f2ffa710"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.2.10-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
      "Collecting langchain-core<0.4.0,>=0.3.21 (from langchain-openai)\n",
      "  Downloading langchain_core-0.3.21-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai) (0.1.143)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai) (24.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai) (9.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.21->langchain-openai) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.21->langchain-openai) (1.0.0)\n",
      "Downloading langchain_openai-0.2.10-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.21-py3-none-any.whl (409 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.5/409.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tiktoken, langchain-core, langchain-openai\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.19\n",
      "    Uninstalling langchain-core-0.3.19:\n",
      "      Successfully uninstalled langchain-core-0.3.19\n",
      "Successfully installed langchain-core-0.3.21 langchain-openai-0.2.10 tiktoken-0.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 openai langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "OtOwaI-eKVQI",
    "outputId": "acd653b3-0db8-4bdc-df4a-320361630961"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Consult with AI Neurologist with Lyzr Automata, Streamlit and\\xa0OpenAI - DEV Community\\nSkip to content\\nNavigation menu\\nSearch\\nPowered by\\nSearch\\nAlgolia\\nSearch\\nLog in\\nCreate account\\nDEV Community\\nClose\\nAdd reaction\\nLike\\nUnicorn\\nExploding Head\\nRaised Hands\\nFire\\nJump to Comments\\nSave\\nBoost\\nMore...\\nCopy link\\nCopy link\\nCopied to Clipboard\\nShare to X\\nShare to LinkedIn\\nShare to Facebook\\nShare to Mastodon\\nReport Abuse\\nharshit-lyzr\\nPosted on\\nApr 30\\nConsult with AI Neurologist with Lyzr Automata, Streamlit and\\xa0OpenAI\\n# openai\\n# healthcare\\n# lyzr\\n# ai\\nIn the ever-evolving landscape of healthcare technology, the integration of artificial intelligence (AI) has revolutionized various medical domains. One such application is the development of consultation tools that aid healthcare professionals in providing efficient and accurate assessments. In this blog post, we\\'ll explore how to build a Neurology Consultant app using Streamlit and OpenAI, enabling streamlined interactions and insights.\\nLyzr.ai\\nCheck out the Lyzr.ai community on Discord – hang out with 338 other members and enjoy free voice and text chat.\\ndiscord.com\\nSetting Up the Environment\\nImports:\\npip install lyzr_automata streamlit\\nimport streamlit as st\\nfrom lyzr_automata.ai_models.openai import OpenAIModel\\nfrom lyzr_automata import Agent,Task\\nfrom lyzr_automata.pipelines.linear_sync_pipeline import LinearSyncPipeline\\nfrom PIL import Image\\nfrom dotenv import load_dotenv\\nimport os\\nfrom prompt import example\\nload_dotenv()\\napi = os.getenv(\"OPENAI_API_KEY\")\\nEnter fullscreen mode\\nExit fullscreen mode\\nImports necessary libraries like streamlit, dotenv, PIL, and custom libraries for Lyzr Automata.\\nLoads environment variables using load_dotenv (likely containing the OpenAI API key).\\nload_dotenv() is called to load environment variables from a\\xa0.env file (likely containing your OpenAI API key).\\napi = os.getenv(\"OPENAI_API_KEY\") retrieves the API key from the environment variable.\\nOpenAI Model Setup:\\nopen_ai_text_completion_model = OpenAIModel(\\napi_key=api,\\nparameters={\\n\"model\": \"gpt-4-turbo-preview\",\\n\"temperature\": 0.2,\\n\"max_tokens\": 1500,\\n},\\n)\\nEnter fullscreen mode\\nExit fullscreen mode\\nThe OpenAIModel class from lyzr_automata is used to create an instance of the OpenAI text completion model (open_ai_text_completion_model).\\nIt sets the API key, model name (\"gpt-4-turbo-preview\"), temperature (0.2), and maximum output length (1500 tokens).\\nUser Input:\\nquery=st.text_area(\"Enter your conversation: \")\\nEnter fullscreen mode\\nExit fullscreen mode\\nquery: Creates a text area for the user to input their conversation prompt.\\nNeurology Consultation Function:\\ndef neurology_consult(query):\\nneurology_agent = Agent(\\nrole=\"Neurology expert\",\\nprompt_persona=f\"You are an Expert neurologist.your task is to create medical note from {query}.\"\\n)\\nneurology_task = Task(\\nname=\"Neurology Consult\",\\nmodel=open_ai_text_completion_model,\\nagent=neurology_agent,\\ninstructions=prompt,\\n)\\noutput = LinearSyncPipeline(\\nname=\"Neurology Consult Pipline\",\\ncompletion_message=\"pipeline completed\",\\ntasks=[\\nneurology_task\\n],\\n).run()\\nanswer = output[0][\\'task_output\\']\\nreturn answer\\nEnter fullscreen mode\\nExit fullscreen mode\\ndef neurology_consult(query):: Defines a function neurology_consult that takes query as input.\\nAgent Definition:\\nneurology_agent = Agent(...): Creates an Agent object with the following properties:\\nrole: Sets the agent\\'s role to \"Neurology expert\".\\nprompt_persona: Defines the agent\\'s persona using a prompt string, indicating its task is to create a medical note based on the query.\\nTask Definition:\\nneurology_task = Task(...): Creates a Task object with the following properties:\\nname: Sets the task name to \"Neurology Consult\".\\nmodel: Sets the model to use (the open_ai_text_completion_model created earlier)\\nConversation Pipeline:\\nLinearSyncPipeline(...): Creates a LinearSyncPipeline object, likely from lyzr_automata, which manages the conversation flow between the user and the neurology agent.\\nname: Sets the pipeline name to \"Neurology Consult Pipline\".\\ncompletion_message: Sets the message displayed when the pipeline finishes (\"pipeline completed\").\\ntasks: Defines a list of tasks within the pipeline, in this case, it only has one task:\\nneurology_task: The previously defined task for the neurology consultation.\\n.run(): Executes the LinearSyncPipeline, running the neurology consultation task.\\nOutput:\\nif st.button(\"Consult\"):\\nsolution = neurology_consult(query)\\nst.markdown(solution)\\nEnter fullscreen mode\\nExit fullscreen mode\\nif st.button(\"Consult\"):: Creates a button labeled \"Consult\". When the button is clicked, the following code executes.\\nsolution = neurology_consult(query): Calls the neurology_consult function with the user\\'s input (query) and stores the generated medical note in the solution variable.\\nst.markdown(solution): Displays the generated medical note as formatted markdown text in the Streamlit app.\\ntry it now:\\nhttps://lyzr-neurology-consultant.streamlit.app/\\nFor more information explore the website:\\nLyzr\\nTop comments\\n(0)\\nSubscribe\\nPersonal\\nTrusted User\\nCreate template\\nTemplates let you quickly answer FAQs or store snippets for re-use.\\nSubmit\\nPreview\\nDismiss\\nCode of Conduct\\n•\\nReport abuse\\nAre you sure you want to hide this comment? It will become hidden in your post, but will still be visible via the comment\\'s\\npermalink .\\nHide child comments as well\\nConfirm\\nFor further actions, you may consider blocking this person and/or\\nreporting abuse\\nRead next\\nHow to Use Napkin AI: Transform Text into Visual Sketches\\nVladislav Guzey -\\nNov 25\\nUnlocking River Valley Loss Landscapes: Why Warmup-Stable-Decay Learning Rates Excel\\nMike Young -\\nNov 2\\nUnlocking Efficient Training for AI Language Giants: Deep Optimizer States\\nMike Young -\\nNov 2\\nAssemblyAI challenge site deployed! Woooohooo check it out! https://speech.vicentereyes.org also check the blog post here!!https://dev.to/highcenburg/speech-to-musical-notation-with-assemblyai-50id\\nVicente G. Reyes -\\nNov 24\\nharshit-lyzr\\nFollow\\nJoined\\nMar 14, 2024\\nMore from\\nharshit-lyzr\\nAI Agents for Effortless Mindmap Generation\\n# ai\\n# powerfuldevs\\n# mindmap\\n# openai\\nBuilding a Loan Underwriting Expert with Lyzr Automata,Streamlit and OpenAI\\n# webdev\\n# python\\n# openai\\n# beginners\\nAutomating YouTube Script Writing with Lyzr Automata\\n# lyzr\\n# openai\\n# opensource\\n# beginners\\nThank you to our Diamond Sponsor\\nNeon\\nfor supporting our community.\\nDEV Community\\n— A constructive and inclusive social network for software developers. With you every step of your journey.\\nHome\\nDEV++\\nPodcasts\\nVideos\\nTags\\nDEV Help\\nForem Shop\\nAdvertise on DEV\\nDEV Challenges\\nDEV Showcase\\nAbout\\nContact\\nFree Postgres Database\\nGuides\\nSoftware comparisons\\nCode of Conduct\\nPrivacy Policy\\nTerms of use\\nBuilt on\\nForem\\n— the\\nopen source\\nsoftware that powers\\nDEV\\nand other inclusive communities.\\nMade with love and\\nRuby on Rails . DEV Community\\n©\\n2016 - 2024.\\nWe\\'re a place where coders share, stay up-to-date and grow their careers.\\nLog in\\nCreate account'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_text_from_url(url):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "      soup = BeautifulSoup(response.text, 'html.parser')\n",
    "      for script_or_style in soup(['script', 'style']):\n",
    "          script_or_style.decompose()\n",
    "\n",
    "      texto = soup.get_text(separator= ' ')\n",
    "      #Limpar texto\n",
    "      linhas = (line.strip() for line in texto.splitlines())\n",
    "      parts = (phrase.strip() for line in linhas for phrase in line.split(\"  \"))\n",
    "      texto_limpo = '\\n'.join(part for part in parts if part)\n",
    "      return texto_limpo\n",
    "    else:\n",
    "        raise ValueError(f\"Failed to fetch the URL. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "    return text\n",
    "\n",
    "\n",
    "extract_text_from_url(\"https://dev.to/harshitlyzr/consult-with-ai-neurologist-with-lyzr-automata-streamlit-and-openai-2c21\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "Cv9sMNeGMEAI",
    "outputId": "282854c8-0419-435b-d0c4-8d6e717746c4"
   },
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models.azure import AzureChatOpenAI\n",
    "\n",
    "client = AzureChatOpenAI(\n",
    "    azure_endpoint=\"https://oai-dio-dev-eastus-01.openai.azure.com/\",\n",
    "    api_key = \"chave-da-API\",\n",
    "    api_version= \"2024-08-01-preview\",\n",
    "    deployment_name = \"gpt-4o-mini\",\n",
    "    max_retries=0\n",
    ")\n",
    "\n",
    "def translate_article(text, lang):\n",
    "  messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Você atua como tradutor de textos.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Traduza o seguinte texto para {lang}: {text}\"}\n",
    "]\n",
    "\n",
    "\n",
    "  response = client.invoke(messages)\n",
    "  print(response.content)\n",
    "  return response.response\n",
    "\n",
    "translate_article(\"The OpenAIModel class from lyzr_automata is used to create an instance of the OpenAI text completion model (open_ai_text_completion_model).\", \"portugues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "56Czlh1sQM4A",
    "outputId": "97126f78-a945-4a1c-a6fd-ae2e16d63a97"
   },
   "outputs": [],
   "source": [
    "url = \"https://dev.to/harshitlyzr/consult-with-ai-neurologist-with-lyzr-automata-streamlit-and-openai-2c21\"\n",
    "text = extract_text_from_url(url)\n",
    "article = translate_article(text, \"pt-br\")\n",
    "\n",
    "print(article)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
